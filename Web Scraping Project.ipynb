{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95483eee-1510-42a1-b0bd-40c3f527e661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "860b7aee-8363-4b12-a8fa-b6370e6c97ef",
   "metadata": {},
   "source": [
    "# WEb Scraping Project\n",
    "## Problem Statement\n",
    "\n",
    "An international firm that is looking to expand its business in different countries across the world wants to creat an automated script that can extract the list of all countries in order of their GDPs in billion USDs (rounded to 2 decimal places), as logged by the International Monetary Fund (IMF). Since IMF releases this evaluation twice a year, this code will be used by the organization to extract the information as it is updated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1104c7aa-072c-4783-8428-6ef52f094865",
   "metadata": {},
   "source": [
    "The required data is available on the URL mentioned below:\n",
    "\n",
    "URL\n",
    "\n",
    "1\n",
    "'https://web.archive.org/web/20230902185326/https://en.wikipedia.org/wiki/List_of_countries_by_GDP_%28nominal%29'\n",
    "\n",
    "The required information needs to be made accessible as a `CSV` file `Countries_by_GDP.csv` as well as a table `Countries_by_GDP` in a database file `World_Economies.db` with attributes `Country` and `GDP_USD_billion`.\n",
    "\n",
    "We will demonstrate the success of this code by running a query on the database table to display only the entries with more than a 100 billion USD economy. Also, you should log in a file with the entire process of execution named etl_project_log.txt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf69604-510b-43bf-8c31-958c4321eeca",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "we have to complete the following tasks for this project\n",
    "\n",
    "1. Write a data extraction function to retrieve the relevant information from the required URL.\n",
    "\n",
    "2. Transform the available GDP information into 'Billion USD' from 'Million USD'.\n",
    "\n",
    "3. Load the transformed information to the required CSV file and as a database file.\n",
    "\n",
    "4. Run the required query on the database.\n",
    "\n",
    "5. Log the progress of the code with appropriate timestamps.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d593239-ba18-4d5a-8e70-229a2a4d8a41",
   "metadata": {},
   "source": [
    "## Initial setup\n",
    "Before we start building the code, we need to install the required libraries for it.\n",
    "\n",
    "The libraries needed for the code are as follows:\n",
    "\n",
    "1. requests - The library used for accessing the information from the URL.\n",
    "\n",
    "2. bs4 - The library containing the BeautifulSoup function used for webscraping.\n",
    "\n",
    "3. pandas - The library used for processing the extracted data, storing it to required formats and communicating with the databases.\n",
    "\n",
    "4. sqlite3 - The library required to create a database server connection.\n",
    "\n",
    "5. numpy - The library required for the mathematical rounding operation as required in the objectives.\n",
    "\n",
    "6. datetime - The library containing the function datetime used for extracting the timestamp for logging purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b26d3d-d215-4aa4-9158-adba3542598f",
   "metadata": {},
   "source": [
    "## Preliminary: Importing libraries and defining known values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5619be2f-3eeb-4760-a12b-d999105dd5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e84056-c655-4b30-a31d-810fed14949b",
   "metadata": {},
   "source": [
    "We will import the URL into this Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07742df7-d7f5-42a5-b25a-6e304a603341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://web.archive.org/web/20230902185326/https://en.wikipedia.org/wiki/List_of_countries_by_GDP_%28nominal%29'\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(\"source.zip\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    print(\"File downloaded successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5806882-da38-442e-a93d-69d6fe6c4540",
   "metadata": {},
   "source": [
    "**Further, we need to initialize all the known entities. These are mentioned below**:\n",
    "\n",
    "**table_attribs**: The attributes or column names for the dataframe stored as a list. Since the data available in the website is in USD Millions, the attributes should initially be 'Country' and 'GDP_USD_millions'. This will be modified in the transform function later.\n",
    "\n",
    "**db_name**: As mentioned in the Project scenario, 'World_Economies.db'\n",
    "\n",
    "**table_name**: As mentioned in the Project scenario, 'Countries_by_GDP'\n",
    "\n",
    "**csv_path**: As mentioned in the Project scenario, 'Countries_by_GDP.csv'\n",
    "\n",
    "We will log the initialization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d42b0c3-fde6-4963-aa25-12e2a7d7b764",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://web.archive.org/web/20230902185326/https://en.wikipedia.org/wiki/List_of_countries_by_GDP_%28nominal%29'\n",
    "table_attribs = [\"Country\", \"GDP_USD_millions\"]\n",
    "db_name = 'World_Economies.db'\n",
    "table_name = 'Countries_by_GDP'\n",
    "csv_path = './Countries_by_GDP.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822c88b2-221e-471b-ab89-058ad732e45d",
   "metadata": {},
   "source": [
    "The Table of interest in the web page is the image below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3a4916-7986-492e-89be-32f7320b725a",
   "metadata": {},
   "source": [
    "**Note**\n",
    "To upload an Imaage file in Jupyter Notebook we do the following\n",
    "1. Upload the Image file(GDP) in the same directory as your Jupyter Notebook\n",
    "2. copy the path eg. *GDP.PNG*\n",
    "3. convert the cell to **markdown**\n",
    "4. in the cell type the following comand ![Title](file Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc443186-b039-4a4d-b00a-9a24b2d02759",
   "metadata": {},
   "source": [
    "![Title](GDP.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fb2cba-7f42-4c9c-a605-3ede81ab61b5",
   "metadata": {},
   "source": [
    "## Task 1: Extracting information\n",
    "\n",
    "Extraction of information from a web page is done using the web scraping process. For this, we'll have to analyze the link by going to the web page and coming up a strategy of how to get the required information. In our case we'll do the following.\n",
    "\n",
    "1. Inspect the URL and note the position of the table. Note that even the images with captions in them are stored in tabular format. Hence, in the given webpage, our table is at the third position, or **index 2**. Among this, we require the entries under 'Country/Territory' and 'IMF -> Estimate'.\n",
    "\n",
    "2. Note that there are a few entries in which the IMF estimate is shown to be '—'. Also, there is an entry at the top named 'World', which we do not require. Segregate this entry from the others because this entry does not have a hyperlink and all others in the table do. So you can take advantage of that and access only the rows for which the entry under 'Country/Terriroty' has a hyperlink associated with it.\n",
    "\n",
    "Note that '—' is a special character and not a general hyphen, '-'. Copy the character from the instructions here to use in the code.\n",
    "\n",
    "We'll create a function `extract()` the function gets the URL and the table_attribs parameters as arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d315ba-80d3-41dd-b2f8-fa0bbb140a06",
   "metadata": {},
   "source": [
    "#### Method\n",
    "1. Extract the web page as text\n",
    "by using this code: `page = requests.get(url).text`\n",
    "\n",
    "2. Parse the text into an HTML object\n",
    "this is done by the code : `data = BeautifulSoup(page,'html.parser')`\n",
    "\n",
    "3. Create an empty pandas DataFrame named `df` with columns as the table_attribs\n",
    "Using this code  `df = pd.DataFrame(columns=table_attribs)`\n",
    "4. Extract all 'tbody' attributes of the HTML object and then extract all the rows of the index 2 table using the 'tr' attribute.\n",
    "\n",
    "   Using the code\n",
    "\n",
    "   `tables = data.find_all('tbody')`\n",
    "   \n",
    "    `rows = tables[2].find_all('tr')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5cc69f-c5fe-4b90-ada4-d5ac994d4df8",
   "metadata": {},
   "source": [
    "5. Check the contents of each row, having attribute ‘td’, for the following conditions(`for row in rows:)\n",
    "* The row should not be empty.(`if len(col)!=0:`)\n",
    "* The first column should contain a hyperlink.(`if col[0].find('a') is not None`)\n",
    "* The third column should not be '—'.(`and '—' not in col[2]:`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a74f791-7ad8-457a-94c5-b0cbe7f2ee0f",
   "metadata": {},
   "source": [
    "6. Store all entries matching the conditions in step 5 to a dictionary(`data_dict`) with keys the same as entries of table_attribs`[\"Country\", \"GDP_USD_millions\"]`. Append all these dictionaries one by one to the dataframe.\n",
    " \n",
    "data_dict = {\"Country\": col[0].a.contents[0],`\n",
    "\n",
    "             \"GDP_USD_millions\": col[2].contents[0]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "493eb9f5-5a86-4762-b925-09621fc07f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(url, table_attribs):\n",
    "    ''' The purpose of this function is to extract the required\n",
    "    information from the website and save it to a dataframe. The\n",
    "    function returns the dataframe for further processing. '''\n",
    "    page = requests.get(url).text\n",
    "    data = BeautifulSoup(page,'html.parser')\n",
    "    df = pd.DataFrame(columns=table_attribs)\n",
    "    tables = data.find_all('tbody')\n",
    "    rows = tables[2].find_all('tr')\n",
    "    for row in rows:\n",
    "        col = row.find_all('td')\n",
    "        if len(col)!=0:\n",
    "            if col[0].find('a') is not None and '—' not in col[2]:\n",
    "                data_dict = {\"Country\": col[0].a.contents[0],\n",
    "                             \"GDP_USD_millions\": col[2].contents[0]}\n",
    "                df1 = pd.DataFrame(data_dict, index=[0])\n",
    "                df = pd.concat([df,df1], ignore_index=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119c1510-5dae-472a-9bac-8b8a4cdcc8e6",
   "metadata": {},
   "source": [
    "We will call up the Function `extract(url, table_attribs)` and use the `.head()`  to see the 1st 5 rows of the dataset to confirm the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82b6c40e-8543-45f6-b360-8cdd3b978ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>GDP_USD_millions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>26,854,599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China</td>\n",
       "      <td>19,373,586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japan</td>\n",
       "      <td>4,409,738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Germany</td>\n",
       "      <td>4,308,854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India</td>\n",
       "      <td>3,736,882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Country GDP_USD_millions\n",
       "0  United States       26,854,599\n",
       "1          China       19,373,586\n",
       "2          Japan        4,409,738\n",
       "3        Germany        4,308,854\n",
       "4          India        3,736,882"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract(url, table_attribs).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babe8fe5-2175-4f4f-9844-279989d1a221",
   "metadata": {},
   "source": [
    "## Task 2: Transform information\n",
    "The transform function needs to modify the `‘GDP_USD_millions’`. We need to cover the following points as a part of the transformation process.\n",
    "\n",
    "1. Convert the contents of the 'GDP_USD_millions' column of df dataframe from currency format to a floating numbers using the following\n",
    "    *  `tolist` to convert toa list\n",
    "    *  `split(',')` to split the content of each cell by the delimeter (,) thus removing the (',') from the cell eg **:\"26\" \"854\" \"599\"**\n",
    "    *  `join()`join the separated cell contents noting you re joing elements separated by \"\" therefore we use `\"\".join(x.split(','))`\n",
    "    *  `float` convert to contents to float\n",
    "2. Divide all these values by 1000 and round it to 2 decimal places\n",
    "3. Modify the name of the column from 'GDP_USD_millions' to 'GDP_USD_billions'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d4a1dfb-3b42-4d99-9775-0e0971929a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    GDP_list = df[\"GDP_USD_millions\"].tolist()\n",
    "    GDP_list = [float(\"\".join(x.split(','))) for x in GDP_list]\n",
    "    GDP_list = [np.round(x/1000,2) for x in GDP_list]\n",
    "    df[\"GDP_USD_millions\"] = GDP_list\n",
    "    df=df.rename(columns = {\"GDP_USD_millions\":\"GDP_USD_billions\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbe6511-c6eb-420b-bf9b-96702f13984d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d7c658a-76f2-462e-94d3-77ca40894853",
   "metadata": {},
   "source": [
    "Lets call-up the fuction `transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2faf29dd-5e32-40b1-9791-203e1a56b911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>GDP_USD_billions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>26854.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China</td>\n",
       "      <td>19373.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japan</td>\n",
       "      <td>4409.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Germany</td>\n",
       "      <td>4308.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India</td>\n",
       "      <td>3736.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Country  GDP_USD_billions\n",
       "0  United States          26854.60\n",
       "1          China          19373.59\n",
       "2          Japan           4409.74\n",
       "3        Germany           4308.85\n",
       "4          India           3736.88"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform(extract(url, table_attribs)).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db51a32-8ee7-4446-8d8e-8588f4d192eb",
   "metadata": {},
   "source": [
    "## Task 3: Loading information\n",
    "Loading process for this project is two fold.\n",
    "\n",
    "We'll have to save the transformed dataframe to a `CSV` file. For this, pass the dataframe df and the CSV file path to the function `load_to_csv()` and add the required statements there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dea6598-2632-40f5-bdc0-0a8621c34826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_csv(df, csv_path):\n",
    "    df.to_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ba5f37-59ec-490f-9833-e2d8506fb3a4",
   "metadata": {},
   "source": [
    "We'll have to save the transformed dataframe as a table in the database. This needs to be implemented in the function `load_to_db()`, which accepts the dataframe df, the connection object to the SQL database conn, and the table name variable table_name to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b195a794-c99d-43c4-aeec-5c9e39304987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_db(df, sql_connection, table_name):\n",
    "    df.to_sql(table_name, sql_connection, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931b2248-d833-4c4b-9680-4cc6fe899827",
   "metadata": {},
   "source": [
    "## Task 4: Querying the database table\n",
    "We'll create a function `run_query(query_statement, sql_connection)` so that when we initiate an appropriate querry statement and pass it to the function `run_query()`, along with the SQL connection object sql_connection and the table name variable `table_name`, this function(`run_query()`) should run the query statement on the table and retrieve the output as a filtered dataframe. This dataframe can then be simply printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e43dfb9e-1230-42ce-861e-c40eb582f7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query_statement, sql_connection):\n",
    "    print(query_statement)\n",
    "    query_output = pd.read_sql(query_statement, sql_connection)\n",
    "    print(query_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a24357-79dc-4390-8361-e37d6b422b51",
   "metadata": {},
   "source": [
    "## Task 5: Logging progress\n",
    "Logging needs to be done using the `log_progress()` funciton. This function will be called multiple times throughout the execution of this code and will be asked to add a log entry in a .txt file, etl_project_log.txt. The entry will be in the following format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "111058f8-c01d-4dd4-8eb3-23d32f586982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(message): \n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second \n",
    "    now = datetime.now() # get current timestamp \n",
    "    timestamp = now.strftime(timestamp_format) \n",
    "    print(timestamp + ' : ' + message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7321b83d-f5a8-4991-b9e1-2af4431ea138",
   "metadata": {},
   "source": [
    "## Function calls\n",
    "Now, you have to set up the sequence of function calls for your assigned tasks. Follow the sequence below.\n",
    "\n",
    "**Task**|\t**Log message on completion**\n",
    "Declaring known values |\tPreliminaries complete. Initiating ETL process.\n",
    "Call extract() | function\tData extraction complete. Initiating Transformation process.\n",
    "Call transform() | function\tData transformation complete. Initiating loading process.\n",
    "Call load_to_csv()\t| Data saved to CSV file.\n",
    "Initiate SQLite3 connection\t| SQL Connection initiated.\n",
    "Call load_to_db()\t| Data loaded to Database as table. Running the query.\n",
    "Call run_query() *\t| Process Complete.\n",
    "Close SQLite3 connection\t-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a74fa6fa-1bc5-48d1-bcc6-acffcef176e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-May-17-11:20:44 : Preliminaries complete. Initiating ETL process\n",
      "2024-May-17-11:20:47 : Data extraction complete. Initiating Transformation process\n",
      "2024-May-17-11:20:47 : Data transformation complete. Initiating loading process\n",
      "2024-May-17-11:20:47 : Data saved to CSV file\n",
      "2024-May-17-11:20:47 : SQL Connection initiated.\n",
      "2024-May-17-11:20:48 : Data loaded to Database as table. Running the query\n",
      "SELECT * from Countries_by_GDP WHERE GDP_USD_billions >= 100\n",
      "          Country  GDP_USD_billions\n",
      "0   United States          26854.60\n",
      "1           China          19373.59\n",
      "2           Japan           4409.74\n",
      "3         Germany           4308.85\n",
      "4           India           3736.88\n",
      "..            ...               ...\n",
      "64          Kenya            118.13\n",
      "65         Angola            117.88\n",
      "66           Oman            104.90\n",
      "67      Guatemala            102.31\n",
      "68       Bulgaria            100.64\n",
      "\n",
      "[69 rows x 2 columns]\n",
      "2024-May-17-11:20:48 : Process Complete.\n"
     ]
    }
   ],
   "source": [
    "log_progress('Preliminaries complete. Initiating ETL process')\n",
    "\n",
    "df = extract(url, table_attribs)\n",
    "\n",
    "log_progress('Data extraction complete. Initiating Transformation process')\n",
    "\n",
    "df = transform(df)\n",
    "\n",
    "log_progress('Data transformation complete. Initiating loading process')\n",
    "\n",
    "load_to_csv(df, csv_path)\n",
    "\n",
    "log_progress('Data saved to CSV file')\n",
    "\n",
    "sql_connection = sqlite3.connect('World_Economies.db')\n",
    "\n",
    "log_progress('SQL Connection initiated.')\n",
    "\n",
    "load_to_db(df, sql_connection, table_name)\n",
    "\n",
    "log_progress('Data loaded to Database as table. Running the query')\n",
    "\n",
    "query_statement = f\"SELECT * from {table_name} WHERE GDP_USD_billions >= 100\"\n",
    "run_query(query_statement, sql_connection)\n",
    "\n",
    "log_progress('Process Complete.')\n",
    "\n",
    "sql_connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306d879a-e214-42e8-8b41-9d7782959805",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this project, we performed complex Extract, Transform, and Loading operations on data from a webpage\n",
    "We achieved the following\n",
    "\n",
    "1. Extract relevant information from websites using Webscraping and requests API.\n",
    "2. Transform the data to a required format.\n",
    "3. Load the processed data to a local file or as a database table.\n",
    "4. Query the database table using Python.\n",
    "5. Create detailed logs of all operations conducted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06745e7-84f2-4a79-b05a-9f5f45f17dea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
